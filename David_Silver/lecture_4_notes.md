## Model-Free Prediction
### Introduction
- Known MDP using dynamic programming vs unknown MDP using model-free methods

### Monte-Carlo Learning
- learn directly from episodes of experience
- model-free: no knowledge of MDP transitions/ rewards
- no bootstraping
- idea: value = mean return instead of expected return
- only applicable to episodic MDPs

First-visit Monte-Carlo Policy Evaluation
- To evaluate state s
- The first time-step 
### Temporal-Difference Learning
### TD(Î»)
